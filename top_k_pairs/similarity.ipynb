{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import pymongo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δεδομένων όλων των ομιλιών, πρέπει να ανιχνεύσουμε ομοιότητες ανά ζεύγη μεταξύ των μελών του κοινοβουλίου. Συγκεκριμένα, πρέπει να βρούμε έναν τρόπο να εξαγάγουμε ένα διάνυσμα χαρακτηριστικών για κάθε μέλος και στη συνέχεια να εκτελέσουμε ομοιότητες ανά ζεύγη για να μπορέσουμε να ανιχνεύσουμε τα top-k ζεύγη με τον υψηλότερο βαθμό ομοιότητας (όπου k είναι μια παράμετρος)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT TO DATABASE\n",
    "mongo_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "client = mongo_client[\"GreekParliamentProceedings\"]\n",
    "index = client[\"InvertedIndex\"]\n",
    "database = client[\"Database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ KEYWORDS BY MEMBER\n",
    "with open('../keywords/member_keywords.pickle', 'rb') as handle:\n",
    "    keywords_by_member = pickle.load(handle)\n",
    "keywords = keywords_by_member"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Διάνυσμα χαρακτηριστικών για κάθε μέλος"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE A FEATURE VECTOR FOR EACH MEMBER\n",
    "member_names = keywords_by_member.keys()\n",
    "genders = []\n",
    "political_parties = []\n",
    "member_roles = []\n",
    "regions = []\n",
    "governments = []\n",
    "def get_attributes_by_member(members, collection):\n",
    "        \"\"\"Creates an attribute vector for each member in a list of members.\n",
    "        The attributes are gathered from a MongoDB collection.\n",
    "        Each member has the following attributes: \n",
    "            name, gender, political parties, roles, regions, governments, keywords\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        members : list\n",
    "            The names of the members\n",
    "        \n",
    "        collection: pymongo.collection.Collection\n",
    "            A collection which includes information about the member attributes.\n",
    "            The collection documents must include the following fields:\n",
    "            'member_name', 'roles', 'member_gender', 'government', 'political_party', 'member_region'\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        genders = []\n",
    "        political_parties = []\n",
    "        member_roles = []\n",
    "        regions = []\n",
    "        governments = []\n",
    "        for member in members:\n",
    "                pipeline = [{'$match' : {'member_name':member}},\n",
    "                            {'$facet': {\n",
    "                                'groupByRoles':[{'$group':{'_id':'$roles'}}],\n",
    "                                'groupByGender':[{'$group':{'_id':'$member_gender'}}],\n",
    "                                'groupByGovernment':[{'$group':{'_id':'$government'}}],\n",
    "                                'groupByParty':[{'$group':{'_id':'$political_party'}}],\n",
    "                                'groupByRegion':[{'$group':{'_id':'$member_region'}}]\n",
    "                            }\n",
    "                                        }\n",
    "                        ]\n",
    "                r = list(collection.aggregate(pipeline))\n",
    "                genders.append(r[0]['groupByGender'][0]['_id'])\n",
    "                regions.append([r[0]['groupByRegion'][i]['_id'] for i in range(len(r[0]['groupByRegion']))])\n",
    "                member_roles.append([r[0]['groupByRoles'][i]['_id'] for i in range(len(r[0]['groupByRoles']))])\n",
    "                governments.append([r[0]['groupByGovernment'][i]['_id'] for i in range(len(r[0]['groupByGovernment']))])\n",
    "                political_parties.append([r[0]['groupByParty'][i]['_id'] for i in range(len(r[0]['groupByParty']))])\n",
    "                \n",
    "        return genders, regions, political_parties, member_roles, governments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders, regions, political_parties, member_roles, governments = get_attributes_by_member(member_names, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "αβραμακης αντωνιου ελευθεριος\n"
     ]
    }
   ],
   "source": [
    "member_names = list(member_names)\n",
    "print(member_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "member_names = list(member_names)\n",
    "for i in range(len(keywords)):\n",
    "    feature_vectors.append([])\n",
    "    feature_vectors[i].append(member_names[i].split()[0])\n",
    "    feature_vectors[i].append(genders[i])\n",
    "    feature_vectors[i].extend(regions[i][j] for j in range(len(regions[i])))\n",
    "    feature_vectors[i].extend(member_roles[i][j] for j in range(len(member_roles[i])))\n",
    "    feature_vectors[i].extend(governments[i][j] for j in range(len(governments[i])))\n",
    "    feature_vectors[i].extend(political_parties[i][j] for j in range(len(political_parties[i])))\n",
    "    feature_vectors[i].extend(keywords[member_names[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dict = []\n",
    "for i in range(len(keywords)):\n",
    "    vector_dict.append({})\n",
    "    vector_dict[i]['member_name'] = [member_names[i].split()[0]]\n",
    "    vector_dict[i]['gender'] = [genders[i]]\n",
    "    vector_dict[i]['member_roles'] = [member_roles[i][j] for j in range(len(member_roles[i]))]\n",
    "    vector_dict[i]['governments'] = [governments[i][j] for j in range(len(governments[i]))]\n",
    "    vector_dict[i]['political_parties'] = [political_parties[i][j] for j in range(len(political_parties[i]))]\n",
    "    vector_dict[i]['keywords'] = keywords[member_names[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member_name': ['αβραμακης'], 'gender': ['male'], 'member_roles': [\"['βουλευτης']\"], 'governments': [\"['μητσοτακη κυριακου(08/07/2019-28/07/2020)']\"], 'political_parties': ['συνασπισμος ριζοσπαστικης αριστερας'], 'keywords': {'συριζ': 13, 'δημοκρατ': 10, 'νε': 7, 'διαταξ': 7, 'δικαιωμ': 7, 'σερρ': 6}}\n"
     ]
    }
   ],
   "source": [
    "print(vector_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('feature_vectors.pickle', 'wb') as handle:\n",
    "#   pickle.dump(feature_vectors, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('feature_vectors.pickle', 'rb') as handle:\n",
    "    feature_vectors = pickle.load(handle)\n",
    "with open('vector_dict.pickle', 'rb') as handle:\n",
    "    vector_dict = pickle.load(handle)\n",
    "from top_k_pairs import Top_k_Pairs as topk\n",
    "top = topk()\n",
    "pairs = top.get_pairs(10, feature_vectors, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5135135135135135, 0.5142857142857142, 0.5151515151515151, 0.5172413793103449, 0.5185185185185185, 0.52, 0.5217391304347826, 0.5238095238095238, 0.5263157894736842, 0.5294117647058824, 0.5333333333333333, 0.5357142857142857, 0.5384615384615384, 0.5416666666666666, 0.5454545454545454, 0.5483870967741935, 0.55, 0.5526315789473685, 0.5555555555555556, 0.5652173913043478, 0.5714285714285714, 0.575, 0.5757575757575758, 0.5789473684210527, 0.5833333333333334, 0.5882352941176471, 0.5909090909090909, 0.6, 0.6111111111111112, 0.6176470588235294, 0.631578947368421, 0.6470588235294118, 0.7142857142857143, 0.7368421052631579]\n",
      "{0.737: [[1120, 559]], 0.714: [[238, 1487]], 0.647: [[835, 967], [835, 204]], 0.632: [[624, 715], [871, 559]], 0.618: [[185, 1010]], 0.611: [[147, 414]], 0.6: [[1470, 374], [985, 204], [57, 439], [1120, 871]], 0.591: [[1240, 1076]]}\n"
     ]
    }
   ],
   "source": [
    "keys = sorted(list(pairs))\n",
    "print(keys)\n",
    "k = 13\n",
    "i = len(keys)-1\n",
    "topk = {}\n",
    "counter=0\n",
    "if(k<=len(pairs.values())):\n",
    "    while(counter<k):\n",
    "        values = [ pairs[keys[i]][j] for j in range(len(pairs[keys[i]])) ]\n",
    "        if(len(values)>=(k-counter)):\n",
    "            topk[round(keys[i],3)]=values[:(k-counter)]\n",
    "            break\n",
    "        else:\n",
    "            topk[round(keys[i],3)]=values\n",
    "            counter = counter + len(values)\n",
    "            i -= 1\n",
    "        \n",
    "print(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each similarity\n",
    "for key in topk.keys():\n",
    "    #for each pair in similarity\n",
    "    for pair in topk[key]:\n",
    "        #for each feature in the feature vector\n",
    "        results = f\"Members {member_names[pair[0]]} and {member_names[pair[1]]} have a jaccard similarity of {key}. They have similar: \" + \"\\n\"\n",
    "        for feature in vector_dict[pair[0]].keys():\n",
    "            intersection = set(vector_dict[pair[0]][feature]).intersection(set(vector_dict[pair[1]][feature]))\n",
    "            #print(str(intersection))\n",
    "            if(len(intersection)>0):\n",
    "               results = results + \" \" + feature +\": \"+str(intersection) + \"\\n\" \n",
    "    with open(\"topkpairs.txt\", \"a\") as f:\n",
    "        f.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(({1,2}.intersection({3,4}))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
